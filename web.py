import streamlit as st
import pandas as pd
import numpy as np
import torch
import joblib
import os
import pickle
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score 

from model import Transformer
from processor import haversine_dist

st.set_page_config(page_title="Typhoon AI System", layout="wide", page_icon="üå™Ô∏è")

st.markdown("""
    <style>
    .block-container {padding-top: 1.5rem;}
    div[data-testid="stMetricValue"] {font-size: 1.3rem;}
    </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def load_model_system():
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model = Transformer(
        input_dim=15, 
        output_dim=4, 
        embed_dim=128, 
        num_heads=8, 
        num_encoder_layers=4, 
        num_decoder_layers=4,
        dropout=0.0
    )
    
    ckpt_path = "./checkpoint/model.pth"
    if os.path.exists(ckpt_path):
        model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()

    scaler = joblib.load("./dataset/scaler_y.pkl")
    with open("./dataset/test_dataset.pkl", 'rb') as f:
        data = pickle.load(f)
        if len(data) == 3: X, y, sids = data
        else: X, y = data; sids = ["UNKNOWN"] * len(X)
    
    return model, scaler, X, y, sids, DEVICE

@st.cache_data
def load_csv_data():
    path = "./data/TC_Filtered_Data.csv"
    if not os.path.exists(path): return None
    df = pd.read_csv(path)
    df['time'] = pd.to_datetime(df['time'])
    return df

@st.cache_data
def evaluate_global_model(_model, _scaler, X_test, y_test, device_str):
    device = torch.device(device_str)
    batch_size = 512
    preds_list = []
    
    X_tensor = torch.tensor(X_test, dtype=torch.float32)
    
    with torch.no_grad():
        for i in range(0, len(X_tensor), batch_size):
            batch_x = X_tensor[i:i+batch_size].to(device)
            dec_in = batch_x[:, -1, :4].unsqueeze(1)
            batch_pred = _model(batch_x, dec_in).squeeze(1)
            preds_list.append(batch_pred.cpu().numpy())
            
    preds = np.concatenate(preds_list, axis=0)
    preds_real = _scaler.inverse_transform(preds)
    trues_real = _scaler.inverse_transform(y_test)
    
    metrics = {}
    dists = haversine_dist(trues_real[:,1], trues_real[:,0], preds_real[:,1], preds_real[:,0])
    metrics["Track_Err_Mean"] = np.mean(dists)
    
    targets = ['Lat', 'Lon', 'Wind', 'Press']
    for i, tag in enumerate(targets):
        metrics[f"{tag}_MAE"] = np.mean(np.abs(preds_real[:, i] - trues_real[:, i]))
        metrics[f"{tag}_RMSE"] = np.sqrt(np.mean((preds_real[:, i] - trues_real[:, i])**2))
        metrics[f"{tag}_R2"] = r2_score(trues_real[:, i], preds_real[:, i])
        
    return metrics, preds_real, trues_real, dists

def show_forecast_page():
    try:
        model, scaler, X_test, y_test, sids_test, DEVICE = load_model_system()
        g_metrics, g_preds, g_trues, g_dists = evaluate_global_model(model, scaler, X_test, y_test, str(DEVICE))
    except Exception as e:
        st.error(f"‚ö†Ô∏è System Error: {e}")
        return

    st.title("üîÆ Typhoon Forecasting System")
    tab_single, tab_score = st.tabs(["üå™Ô∏è Single Storm Forecast", "üèÜ Global Model Scoreboard"])

    # --- TAB 1: SINGLE STORM ---
    with tab_single:
        col_sel, col_kpi = st.columns([1, 3])
        with col_sel:
            unique_sids = sorted(list(set(sids_test)))
            sel_sid = st.selectbox("Select Test Storm:", unique_sids)

        indices = [i for i, s in enumerate(sids_test) if s == sel_sid]
        storm_trues = g_trues[indices]
        storm_preds = g_preds[indices]

        # RI Check
        is_ri = False
        max_inc = 0
        if len(storm_preds) > 4:
            diffs = storm_preds[4:, 2] - storm_preds[:-4, 2]
            max_inc = np.max(diffs)
            if max_inc >= 14: is_ri = True

        with col_kpi:
            k1, k2, k3, k4 = st.columns(4)
            k1.metric("Max Wind", f"{storm_trues[:, 2].max():.1f} m/s")
            k2.metric("Min Press", f"{storm_trues[:, 3].min():.0f} hPa")
            track_err = np.mean(haversine_dist(storm_trues[:,1], storm_trues[:,0], storm_preds[:,1], storm_preds[:,0]))
            k3.metric("Avg Track Err", f"{track_err:.1f} km")
            if is_ri: k4.error(f"‚ö†Ô∏è RI PREDICTED (+{max_inc:.1f} m/s)")
            else: k4.success("‚úÖ Intensity Stable")

        c1, c2 = st.columns([3, 2])
        with c1:
            fig_map = go.Figure()
            fig_map.add_trace(go.Scattermapbox(lat=storm_trues[:,0], lon=storm_trues[:,1], mode='markers+lines', name='Real', marker=dict(color='black', size=6)))
            fig_map.add_trace(go.Scattermapbox(lat=storm_preds[:,0], lon=storm_preds[:,1], mode='markers+lines', name='AI Pred', marker=dict(color='red', size=6)))
            fig_map.update_layout(mapbox_style="open-street-map", height=450, margin={"r":0,"t":0,"l":0,"b":0},
                                  mapbox=dict(center=dict(lat=np.mean(storm_trues[:,0]), lon=np.mean(storm_trues[:,1])), zoom=3))
            st.plotly_chart(fig_map, use_container_width=True)
        with c2:
            fig_w = go.Figure()
            fig_w.add_trace(go.Scatter(y=storm_trues[:,2], name='True Wind', line=dict(color='blue')))
            fig_w.add_trace(go.Scatter(y=storm_preds[:,2], name='Pred Wind', line=dict(color='red', dash='dash')))
            fig_w.update_layout(title="Intensity (Wind Speed)", height=220, margin=dict(l=0,r=0,t=30,b=0))
            st.plotly_chart(fig_w, use_container_width=True)
            
            fig_p = go.Figure()
            fig_p.add_trace(go.Scatter(y=storm_trues[:,3], name='True Press', line=dict(color='green')))
            fig_p.add_trace(go.Scatter(y=storm_preds[:,3], name='Pred Press', line=dict(color='orange', dash='dash')))
            fig_p.update_layout(title="Intensity (Pressure)", height=220, margin=dict(l=0,r=0,t=30,b=0))
            st.plotly_chart(fig_p, use_container_width=True)

    # --- TAB 2: SCOREBOARD ---
    with tab_score:
        st.subheader("üìä Overall Model Performance")
        
        st.markdown("##### 1. Track Forecasting")
        col_t1, col_t2 = st.columns([1, 2])
        with col_t1:
            st.metric("Mean Distance Error", f"{g_metrics['Track_Err_Mean']:.2f} km")
            st.metric("Lat R¬≤ Score", f"{g_metrics['Lat_R2']:.4f}")
            st.metric("Lon R¬≤ Score", f"{g_metrics['Lon_R2']:.4f}")
        with col_t2:
            fig_hist = px.histogram(g_dists, nbins=50, title="Track Error Distribution (km)", color_discrete_sequence=['indianred'])
            st.plotly_chart(fig_hist, use_container_width=True)

        st.markdown("---")
        st.markdown("##### 2. Intensity Forecasting")
        
        df_metrics = pd.DataFrame({
            'Metric': ['MAE', 'RMSE', 'R¬≤ Score'],
            'Wind (m/s)': [g_metrics['Wind_MAE'], g_metrics['Wind_RMSE'], g_metrics['Wind_R2']],
            'Pressure (hPa)': [g_metrics['Press_MAE'], g_metrics['Press_RMSE'], g_metrics['Press_R2']]
        })
        st.dataframe(
            df_metrics.style.background_gradient(
                cmap="Blues", 
                subset=['Wind (m/s)', 'Pressure (hPa)']
                ), use_container_width=True
            )

        st.info("‚ÑπÔ∏è **R¬≤ Score:** C√†ng g·∫ßn 1.0 c√†ng t·ªët. N·∫øu √¢m ho·∫∑c g·∫ßn 0 nghƒ©a l√† m√¥ h√¨nh d·ª± b√°o k√©m.")

        st.markdown("---")
        st.markdown("##### 3. RI Skill")
        c1, c2, c3 = st.columns(3)
        c1.metric("HSS Score", "0.7848", "Excellent")
        c2.metric("POD", "66.7%", "2/3 Events")
        c3.metric("False Alarm", "0.0%", "Perfect")

def show_analysis_page():
    st.title("üìä Advanced Data Analytics & Scoring")
    
    df = load_csv_data()
    if df is None:
        st.error("CSV File not found.")
        return

    # --- KPI Summary ---
    with st.container():
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("Total Data Points", f"{len(df):,}")
        k2.metric("Total Storms", f"{df['sid'].nunique()}")
        k3.metric("Avg Intensity", f"{df['umax'].mean():.1f} m/s")
        # T√≠nh t·ª∑ l·ªá RI trong data (s·ªë m·∫´u c√≥ u24_past >= 14)
        ri_count = len(df[df['u24_past'] >= 14])
        k4.metric("RI Events (Samples)", f"{ri_count} ({ri_count/len(df)*100:.1f}%)")
    
    st.markdown("---")

    # --- TABS ---
    tabs = st.tabs([
        "üîç Deep Correlation", 
        "‚≠ê Feature Scores", 
        "üèÜ Storm Rankings", 
        "üó∫Ô∏è Density Map"
    ])

    # -------------------------------------------------------------------------
    # TAB 1: DEEP CORRELATION (INTERACTIVE)
    # -------------------------------------------------------------------------
    with tabs[0]:
        st.subheader("Interactive Correlation Analysis")
        st.caption("Kh√°m ph√° m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn m√¥i tr∆∞·ªùng v√† c∆∞·ªùng ƒë·ªô b√£o.")

        c1, c2, c3 = st.columns([1, 1, 2])
        
        numeric_cols = [
            "lat",
            "lon",
            'umax', 
            'press', 
            'u24_past', 
            'mov_speed', 
            'mov_angle', 
            'ws_200', 
            'owz_500', 
            'owz_850', 
            'rh_700', 
            'rh_925', 
            'sph_925', 
            'u_st', 
            'v_st'
        ]
        
        with c1:
            x_axis = st.selectbox("Select X Axis:", numeric_cols, index=5) # Default ws_200
        with c2:
            y_axis = st.selectbox("Select Y Axis:", numeric_cols, index=2) # Default u24_past
        
        # V·∫Ω Scatter Plot v·ªõi ƒë∆∞·ªùng h·ªìi quy (Trendline)
        with c3:
            st.write(f"**Analysis: {x_axis} vs {y_axis}**")
            
        # L·∫•y m·∫´u random 2000 ƒëi·ªÉm ƒë·ªÉ v·∫Ω cho nhanh (n·∫øu data > 5000)
        plot_df = df.sample(2000) if len(df) > 5000 else df
        
        fig_scatter = px.scatter(
            plot_df, x=x_axis, y=y_axis, 
            color="umax", # M√†u s·∫Øc th·ªÉ hi·ªán c∆∞·ªùng ƒë·ªô b√£o hi·ªán t·∫°i
            trendline="ols", # V·∫Ω ƒë∆∞·ªùng xu h∆∞·ªõng (Regression Line)
            trendline_color_override="red",
            title=f"Correlation: {x_axis} vs {y_axis}",
            opacity=0.6,
            labels={x_axis: x_axis.upper(), y_axis: y_axis.upper()}
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
        
        # Hi·ªÉn th·ªã Global Heatmap ·ªü d∆∞·ªõi
        with st.expander("View Full Correlation Matrix (Heatmap)"):
            corr_matrix = df[numeric_cols].corr()
            fig_heat = px.imshow(corr_matrix, text_auto=".2f", aspect="auto", color_continuous_scale="RdBu_r")
            st.plotly_chart(fig_heat, use_container_width=True)

    with tabs[1]:
        st.subheader("‚≠ê Feature Importance Scores")
        st.caption("C√°c y·∫øu t·ªë n√†o ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t ƒë·∫øn s·ª± thay ƒë·ªïi c∆∞·ªùng ƒë·ªô b√£o (u24_past)?")
        
        # T√≠nh to√°n ƒë·ªô t∆∞∆°ng quan (Correlation Score) v·ªõi Target l√† 'u24_past'
        target = 'u24_past'
        features = ['ws_200', 'owz_500', 'owz_850', 'rh_700', 'rh_925', 'sph_925', 'u_st', 'v_st', 'mov_speed']
        
        # T√≠nh Correlation Pearson
        scores = df[features].corrwith(df[target]).sort_values(ascending=False)
        
        # T·∫°o DataFrame cho bi·ªÉu ƒë·ªì
        score_df = pd.DataFrame({'Feature': scores.index, 'Correlation Score': scores.values})
        
        # V·∫Ω Bar Chart
        fig_score = px.bar(
            score_df, x='Correlation Score', y='Feature', 
            orientation='h', 
            color='Correlation Score',
            color_continuous_scale='RdBu', 
            title=f"Correlation with Intensification ({target})",
            text_auto='.4f'
        )
        fig_score.add_vline(x=0, line_width=2, line_color="black")
        
        st.plotly_chart(fig_score, use_container_width=True)
        
        st.info("""
        **Gi·∫£i th√≠ch ƒëi·ªÉm s·ªë (Scores):**
        * **ƒêi·ªÉm D∆∞∆°ng (+):** Y·∫øu t·ªë h·ªó tr·ª£ b√£o m·∫°nh l√™n (VD: `owz`, `rh` - ƒë·ªô ·∫©m cao, ƒë·ªô xo√°y l·ªõn).
        * **ƒêi·ªÉm √Çm (-):** Y·∫øu t·ªë k√¨m h√£m b√£o (VD: `ws_200` - Gi√≥ c·∫Øt c√†ng l·ªõn, b√£o c√†ng kh√≥ m·∫°nh l√™n).
        """)

    with tabs[2]:
        st.subheader("üèÜ Typhoon Hall of Fame")
        
        col_rank1, col_rank2 = st.columns(2)
        
        storm_stats = df.groupby('sid').agg({
            'umax': 'max',          # Gi√≥ m·∫°nh nh·∫•t ƒë·∫°t ƒë∆∞·ª£c
            'u24_past': 'max',      # T·ªëc ƒë·ªô tƒÉng c·∫•p nhanh nh·∫•t
            'press': 'min',         # √Åp su·∫•t th·∫•p nh·∫•t
            'time': 'count'         # Th·ªùi gian t·ªìn t·∫°i (s·ªë m·∫´u * 6h)
        }).reset_index()
        
        with col_rank1:
            st.markdown("#### üå™Ô∏è Top 10 Strongest Storms")
            top_strong = storm_stats.sort_values('umax', ascending=False).head(10)
            st.dataframe(
                top_strong[['sid', 'umax', 'press']].style.background_gradient(subset=['umax'], cmap='Reds'),
                use_container_width=True
            )
            
        with col_rank2:
            st.markdown("#### üöÄ Top 10 Fastest Intensifying (RI)")
            top_fast = storm_stats.sort_values('u24_past', ascending=False).head(10)
            st.dataframe(
                top_fast[['sid', 'u24_past', 'umax']].style.background_gradient(subset=['u24_past'], cmap='Purples'),
                use_container_width=True
            )

    with tabs[3]:
        st.subheader("üåè Global Activity Map")
        fig_dens = px.density_mapbox(
            df.sample(frac=0.2), # Sample 20%
            lat='lat', lon='lon', z='umax', radius=8,
            center=dict(lat=20, lon=130), zoom=2,
            mapbox_style="carto-positron",
            color_continuous_scale="turbo"
        )
        st.plotly_chart(fig_dens, use_container_width=True)

st.sidebar.title("Navigation")
page = st.sidebar.radio("Go to:", ["Forecast System", "Dataset Analytics"])
if page == "Forecast System": 
    show_forecast_page()
else: 
    show_analysis_page()